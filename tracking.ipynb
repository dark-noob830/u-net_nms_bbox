{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: SiamFC Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T16:51:29.215153Z",
     "start_time": "2025-07-20T16:51:18.288482Z"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# ---------- SiamFC Network Definition ----------\n",
    "class SiamFC(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SiamFC, self).__init__()\n",
    "        self.backbone = models.Sequential([\n",
    "            layers.Conv2D(96, kernel_size=11, strides=2, activation='relu', input_shape=(127, 127, 3)),\n",
    "            layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            layers.Conv2D(256, kernel_size=5, activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "            layers.Conv2D(384, kernel_size=3, activation='relu'),\n",
    "            layers.Conv2D(384, kernel_size=3, activation='relu'),\n",
    "            layers.Conv2D(256, kernel_size=3),\n",
    "        ])\n",
    "\n",
    "    def xcorr(self, z, x):\n",
    "        \"\"\"Cross-correlation using depthwise convolution\"\"\"\n",
    "        # Convert z to filter shape (filter_height, filter_width, in_channels, out_channels)\n",
    "        filters = tf.transpose(z, [1, 2, 3, 0])\n",
    "        return tf.nn.conv2d(x, filters, strides=1, padding='VALID')\n",
    "\n",
    "    def call(self, template, search):\n",
    "        z = self.backbone(template)\n",
    "        x = self.backbone(search)\n",
    "        out = self.xcorr(z, x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------- Helper Functions ----------\n",
    "def get_patch(img, center, size, output_size=127):\n",
    "    cx, cy = center\n",
    "    w, h = size\n",
    "    x1 = int(cx - w / 2)\n",
    "    y1 = int(cy - h / 2)\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    imgh, imgw = img.shape[:2]\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(imgw, x2)\n",
    "    y2 = min(imgh, y2)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return np.zeros((output_size, output_size, 3), dtype=np.float32)\n",
    "    patch = img[y1:y2, x1:x2]\n",
    "    patch = cv2.resize(patch, (output_size, output_size))\n",
    "    patch = patch.astype(np.float32) / 255.0\n",
    "    return patch\n",
    "\n",
    "\n",
    "# ---------- Load Video and Template ----------\n",
    "video_path = 'sample_tracking_video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "init_bbox = cv2.selectROI(\"Frame\", first_frame, fromCenter=False, showCrosshair=True)\n",
    "cx, cy = init_bbox[0] + init_bbox[2] // 2, init_bbox[1] + init_bbox[3] // 2\n",
    "\n",
    "# ---------- Prepare SiamFC ----------\n",
    "model = SiamFC()\n",
    "model.build(input_shape=[(1, 127, 127, 3), (1, 127, 127, 3)])\n",
    "\n",
    "# Extract template from initial frame\n",
    "template = get_patch(first_frame, (cx, cy), (init_bbox[2], init_bbox[3]))\n",
    "template_tensor = np.expand_dims(template, axis=0)\n",
    "# ---------- Main Tracking Loop ----------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract search patch\n",
    "    search = get_patch(frame, (cx, cy), (init_bbox[2] * 2, init_bbox[3] * 2), 255)\n",
    "    search_tensor = np.expand_dims(search, axis=0)\n",
    "\n",
    "    # Run SiamFC\n",
    "    response = model(template_tensor, search_tensor)\n",
    "    response_np = response.numpy().squeeze()\n",
    "\n",
    "    # Find peak response\n",
    "    dy, dx = np.unravel_index(np.argmax(response_np), response_np.shape)\n",
    "    dy -= response_np.shape[0] // 2\n",
    "    dx -= response_np.shape[1] // 2\n",
    "    cx += dx\n",
    "    cy += dy\n",
    "\n",
    "    # Draw updated bounding box\n",
    "    top_left = (int(cx - init_bbox[2] / 2), int(cy - init_bbox[3] / 2))\n",
    "    bottom_right = (int(cx + init_bbox[2] / 2), int(cy + init_bbox[3] / 2))\n",
    "    cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
